---
layout: post
title: "如何使用 VMWare 安装 ubuntu"
subtitle: "The Systematic Failure of Higher Education in China"
date: 2025-03-13 23:10:00
author: "NiuHuLu"
catalog: false
published: true
header-style: text
tags:
  - Linux
---
# 八股文
## 高德
- 讲一讲 Transformer 的结构，多头注意力机制的参数量是多少，为什么注意力分数要除以 $\sqrt{dk}$
- RMSNorm 相比 LayerNorm 有什么区别，Pre-Norm 和 Post-Norm 各有什么优劣，现在主流大模型一般用哪种
- 除了多头注意力，还了解哪些注意力的改进，讲一下 GQA 和 MQA。
- DeepSeek-V2 的 MLA 有了解吗，是怎么做的
- 大模型的后训练流程是什么讲一下 LoRA 的原理，参数是怎么初始化的，为什么。
- 除了 LoRA，还了解哪些大模型的微调方法
- leetcode ----72--编辑距离
- 大模型的训练流程是怎样的，目前 RLHF 中主流的强化学习算法有哪些，PPO，DPO 选一个展开讲讲
- 知道哪些在大模型训练或者推理过程中的优化方法，ZeRO、混合精度训练、FlashAttention……
- 知道大模型的参数量是怎么算出来的吗，比如一个 7B 的模型，估算一下参数量
- 目前常用的位置编码有哪些，RoPE 为什么外推性比较好

## 阿里钉钉
### 一面
- 简单介绍一下系统

- 三轮对话准确率如何达到98%

- rag如何提高准确率和召回率

- 如何微调

- 模型选择

- deepseek跟踪的关键技术

### 二面
- rag数据安全问题，权限控制

- 如何进行模型微调
  1. 函数查找的微调以及函数参数的微调
  2. 基础语料的准备，数据增强动作。基于prompt做数据增强动作
  3. 人工的校验
  4. 数据的预处理，格式化处理，组装成多轮对话
  5.  LoRa的微调
  6.  模型的评估的工具
  7.  反复迭代

- 为什么只取三轮对话，多轮对话的准确性
  1
- 长短期记忆如何存储的

- 知识图谱如何实现的

- 对langchain,llamaxindex了解多少

### 三面
- 端到端的流程，架构设计
- 为什么用微调
- prompt如何书写的
  1、
- 为什么不用一个prompt
  1.  三个方面，从设计上来说。Text2API和函数查找实际上是两个类，抽象出来函数查找，应对更多的场景；
  2.  尽管也可以写在一个prompt里面，但是一个prompt带来的上下文长度过长，耗时不见得会快，对于首token的响应速度应该不如短文本.
  3.  函数查找只是查找到唯一一个函数，但是参数解析的时候存在多个函数连续依赖，连续调用的情况，这种情况prompt会比较复杂，所以选择拆解
  
- rag和知识图谱了解多少
- 承担的角色，团队人数
- 部署的gpu卡，微调的卡
- 未来的规划
- AIGC真的会到来吗
- 最近的热点的技术
  1. deepseek
  2. Manus
  3. 具身智能

- ai可以取代人类吗



## 小鹏汽车
- 设计了哪些Agent
- 未来Agent的设计和发展
- 如何进行模型微调的
- plan功能如何实现
- 如何进行模型评估的
- 准确性提升的一个过程



